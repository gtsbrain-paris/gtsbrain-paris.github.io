<!DOCTYPE html>
<html>
  <head>
    <title>GTSBrain Paris - Publications</title>
    <link rel="stylesheet" href="styles.css">
  </head>
  <body>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="events.html">Events</a></li>
        <li><a href="jobs.html">Jobs</a></li>
        <li><a href="contact.html">Contact us</a></li>
      </ul>
    </nav> 
    <div id="main">
      <h2>Publications</h2> 
      <p> The list of publications from <u>members of the team</u> can be found below (*equal contribution).</p>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/dicl.PNG" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/abs/2410.11711", target="_blank">Zero-shot Model-based Reinforcement Learning using Large Language Models</a> </papertitle>
              <br>
              <u>Abdelhakim Benechehab</u>,
              <u>Youssef Attia El Hili</u>,
              <u>Ambroise Odonnat</u>,
              <u>Oussama Zekri</u>,
              <u>Albert Thomas</u>,
              <u>Giuseppe Paolo</u>,
              Maurizio Filippone
              <u>Ievgen Redko</u>,
              <u>Balázs Kégl</u>
              <br>
              <i><strong>ICLR 2025</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2410.11711", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=uZFXpPrwSh", target="_blank">OpenReview</a> / 
              <a href="https://github.com/abenechehab/dicl", target="_blank">code</a>  /
              <p></p>
              <p></p>
            </td>
          </tr>
        
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/visu.PNG" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/pdf/2410.24050", target="_blank">Clustering Head: A Visual Case Study of the Training Dynamics in Transformers</a> </papertitle>
              <br>
              <u>Ambroise Odonnat</u>,
              Wassim Bouaziz,
              Vivien Cabannes
              <br>
              <i><strong>Preprint</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2410.24050", target="_blank">arXiv</a> /
              <a href="https://github.com/facebookresearch/pal", target="_blank">code</a>  / 
              <p></p>
              <p></p>
            </td>
          </tr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/circuit.PNG" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/pdf/2501.02362", target="_blank">Easing Optimization Paths: A Circuit Perspective</a> </papertitle>
              <br>
              <u>Ambroise Odonnat*</u>,
              Wassim Bouaziz*,
              Vivien Cabannes
              <br>
              <i><strong>ICASSP 2025</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2501.02362", target="_blank">arXiv</a> /
              <a href="https://github.com/facebookresearch/pal", target="_blank">code</a>  / 
              <p></p>
              <p></p>
            </td>
          </tr>
                
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/llm_preview.PNG" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/pdf/2410.02724", target="_blank">Large Language Models as Markov Chains</a> </papertitle>
              <br>
              <u>Oussama Zekri*</u>,
              <u>Ambroise Odonnat*</u>,
              <u>Abdelhakim Benechehab</u>,
              Linus Bleistein,
              Nicolas Boulle,
              <u>Ievgen Redko</u>
              <br>
              <i><strong>Preprint</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2410.02724", target="_blank">arXiv</a> /
              <p></p>
              <p></p>
            </td>
          </tr>
        
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/adapter_framework.png" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/abs/2409.12264", target="_blank">User-friendly Foundation Model Adapters for Multivariate Time Series Classification</a> </papertitle>
              <br>
              <u>Romain Ilbert*</u>,
              <u>Vasilii Feofanov*</u>,
              <u>Malik Tiomoko</u>,
              Themis Palpanas,
              <u>Ievgen Redko</u>
              <br>
              <i><strong>Preprint</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2409.12264", target="_blank">arXiv</a> /
              <p></p>
              <p></p>
            </td>
          </tr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/logo_ts.png" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/abs/2406.10327", target="_blank">Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting</a> </papertitle>
              <br>
              <u>Romain Ilbert</u>,
              <u>Malik Tiomoko</u>,
              Cosme Louart,
              <u>Ambroise Odonnat</u>,
              <u>Vasilii Feofanov</u>,
              Themis Palpanas,
              <u>Ievgen Redko</u>
              <br>
              <i><strong>NeurIPS 2024 - Spotlight (top 10%)</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2406.10327", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=FFW6rPz48Z", target="_blank">OpenReview</a> /
              <p></p>
              <p></p>
            </td>
          </tr>
                
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/mano_neurips.png" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/abs/2405.18979", target="_blank">MaNo: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts</a> </papertitle>
              <br>
              Renchunzi Xie*,
              <u>Ambroise Odonnat*</u>,
              <u>Vasilii Feofanov*</u>,
              Weijian Deng,
              Jianfeng Zhang,
              Bo An
              <br>
              <i><strong>NeurIPS 2024</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2405.18979", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=mH1xtt2bJE", target="_blank">OpenReview</a> / 
              <a href="https://github.com/Renchunzi-Xie/MaNo", target="_blank">code</a>  / 
              <p></p>
              <p></p>
            </td>
          </tr>
      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/samformer.PNG" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/pdf/2402.10198", target="_blank">SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention</a> </papertitle>
              <br>
              <u>Romain Ilbert*</u>,
              <u>Ambroise Odonnat*</u>,
              <u>Vasilii Feofanov</u>,
              <u>Aladin Virmaux</u>,
              <u>Giuseppe Paolo</u>,
              Themis Palpanas,
              <u>Ievgen Redko</u>
              <br>
              <i><strong>ICML 2024 - Oral (top 5%)</strong>. Also presented at <a href="https://caprfiap2024.sciencesconf.org/", target="_blank">CAp</a> 2024 (oral).</i>
              <br>
              <a href="https://arxiv.org/abs/2402.10198", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=8kLzL5QBh2", target="_blank">OpenReview</a> /
              <a href="https://github.com/romilbert/samformer", target="_blank">code</a> 
              <p></p>
              <p></p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/prob_bounds_jmlr.png" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://jmlr.org/papers/v25/23-0121.html", target="_blank">Multi-class Probabilistic Bounds for Majority Vote Classifiers with Partially Labeled Data</a> </papertitle>
              <br>
              <u>Vasilii Feofanov</u>,
              Emilie Devijver,
              Massih-Reza Amini
              <br>
              <i><strong>JMLR</strong>. Also presented at <a href="https://icml.cc/", target="_blank">ICML</a> 2024 (poster).</i>
              <br>
              <a href="https://jmlr.org/papers/v25/23-0121.html", target="_blank">Paper</a> /
              <a href="https://icml.cc/virtual/2024/poster/35637", target="_blank">Poster</a> 
              <p></p>
              <p></p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:15%;vertical-align:middle">
              <img src="images/paper_logos/tsim_aistats.png" alt="PontTuset" width="150" style="border-style: none">
            </td>
            <td width="85%" valign="middle">
              <papertitle><a href="https://arxiv.org/pdf/2310.14814", target="_blank">Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias</a> </papertitle>
              <br>
              <u>Ambroise Odonnat</u>,
              <u>Vasilii Feofanov</u>,
              <u>Ievgen Redko</u>
              <br>
              <i><strong>AISTATS 2024</strong>. Also presented at <a href="https://caprfiap2024.sciencesconf.org/", target="_blank">CAp</a> 2024 (long oral).</i>
              <br>
              <a href="https://arxiv.org/abs/2310.14814", target="_blank">arXiv</a> /
              <a href="https://proceedings.mlr.press/v238/odonnat24a", target="_blank">PMLR</a> /
              <a href="https://github.com/ambroiseodt/tsim", target="_blank">code</a> 
              <p></p>
              <p></p>
            </td>
          </tr>
     </div> 
   </body> 
 </html> 
